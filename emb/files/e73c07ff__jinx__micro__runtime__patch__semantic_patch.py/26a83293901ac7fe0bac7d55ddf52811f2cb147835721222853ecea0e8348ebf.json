{"meta": {"ts": 1760763313.2760928, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\runtime\\patch\\semantic_patch.py", "chunk_index": 2, "chunks_total": 5, "content_sha256": "26a83293901ac7fe0bac7d55ddf52811f2cb147835721222853ecea0e8348ebf", "file_sha256": "9f7c29d22941b8a20c0045d10e31443e1561d311ad43e375919e452a331dd8e4", "terms": ["int", "none", "cur", "str", "not", "optional", "file", "float", "margin", "tol", "topk", "else", "except", "exception", "getenv", "try", "window", "bool", "embeddings", "eol", "false", "path", "replacement", "splitlines", "the"], "text_preview": "async def patch_semantic_in_file(path: str, query: str, replacement: str, *, preview: bool = False, topk: Optional[int] = None, margin: Optional[int] = None, tol: Optional[float] = None) -> Tuple[bool, str]:\n    \"\"\"Patch a large file by locating the best i", "dims": 0, "line_start": 74, "line_end": 100}, "embedding": []}