{"meta": {"ts": 1760763310.811736, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\embeddings\\embed_cache.py", "chunk_index": 1, "chunks_total": 6, "content_sha256": "f41a1e37dab0b3f6985da461018f9e13371bf2ca62a19184cd2a215b39665b4e", "file_sha256": "5687542652356ac9e9caeedf34ee15eb9545edb77bc11053b973daf301bafe83", "terms": ["model", "str", "list", "return", "text", "vec", "none", "def", "async", "float", "_mem", "resp", "await", "_dump_line", "_now", "_sem", "_worker", "asyncio", "data", "len", "time", "client", "exp", "max", "not"], "text_preview": "return time.time()\n\n\ndef _cache_get(model: str, text: str) -> List[float] | None:\n    k = (model, text)\n    v = _mem.get(k)\n    if not v:\n        return None\n    exp, vec = v\n    if exp < _now():\n        _mem.pop(k, None)\n        return None\n    return vec", "dims": 0, "line_start": 42, "line_end": 80}, "embedding": []}