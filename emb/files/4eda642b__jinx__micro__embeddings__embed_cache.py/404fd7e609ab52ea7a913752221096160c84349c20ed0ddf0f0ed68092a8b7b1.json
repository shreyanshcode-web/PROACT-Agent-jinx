{"meta": {"ts": 1760763310.8127337, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\embeddings\\embed_cache.py", "chunk_index": 2, "chunks_total": 6, "content_sha256": "404fd7e609ab52ea7a913752221096160c84349c20ed0ddf0f0ed68092a8b7b1", "file_sha256": "5687542652356ac9e9caeedf34ee15eb9545edb77bc11053b973daf301bafe83", "terms": ["model", "return", "list", "await", "texts", "data", "fut", "none", "not", "out", "try", "vec", "_dump_line", "_worker", "asyncio", "str", "batch", "client", "def", "except", "exception", "float", "for", "key", "len"], "text_preview": "await _dump_line(f\"call batch model={model} n={len(texts)}\")\n        def _worker() -> Any:\n            client = get_openai_client()\n            return client.embeddings.create(model=model, input=texts)\n        try:\n            resp = await asyncio.wait_for", "dims": 0, "line_start": 81, "line_end": 115}, "embedding": []}