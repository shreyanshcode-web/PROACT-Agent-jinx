{"meta": {"ts": 1760763311.284742, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\embeddings\\project_stage_cooccur.py", "chunk_index": 1, "chunks_total": 5, "content_sha256": "46a494c2d28f35b49863f82fc9908bed98f0b2f70d3fecea760a9beeb73428c9", "file_sha256": "12007dfefcce9699167e01e296096db97168d4886c99be725c2b246626cb846c", "terms": ["int", "str", "tokens", "lines", "list", "query", "return", "around", "def", "hits", "token", "t_ci", "t_cs", "and", "idx", "least", "len", "lower", "max", "min", "strip", "text", "tuple", "where", "within"], "text_preview": "return toks\n\n\ndef _find_lines(text: str, token: str) -> List[int]:\n    # Case-sensitive then insensitive fallback\n    lines = text.splitlines()\n    hits: List[int] = []\n    t_cs = token\n    t_ci = token.lower()\n    for idx, ln in enumerate(lines, start=1):", "dims": 0, "line_start": 41, "line_end": 74}, "embedding": []}