{"meta": {"ts": 1760763311.2867377, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\embeddings\\project_stage_cooccur.py", "chunk_index": 2, "chunks_total": 5, "content_sha256": "7a75960d3c43e5ca79fe823e7ba8a8a86d81dcfbbc290193f19f135e3a2de04a", "file_sha256": "12007dfefcce9699167e01e296096db97168d4886c99be725c2b246626cb846c", "terms": ["return", "str", "for", "locs", "not", "txt", "list", "false", "len", "tokens", "max_time_ms", "abs_p", "perf_counter", "time_up", "arr", "bool", "continue", "def", "int", "present", "range", "time", "_find_lines", "best_a", "best_b"], "text_preview": "return []\n    t0 = time.perf_counter()\n    out: List[Tuple[float, str, Dict[str, Any]]] = []\n\n    def time_up() -> bool:\n        return max_time_ms is not None and (time.perf_counter() - t0) * 1000.0 > max_time_ms\n\n    def process(abs_p: str, rel_p: str) -", "dims": 0, "line_start": 75, "line_end": 109}, "embedding": []}