{"meta": {"ts": 1760763310.655492, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\conversation\\cont\\classify.py", "chunk_index": 0, "chunks_total": 5, "content_sha256": "7d73ef671907f2ec9bb92ee460834e585a1f33774ddcc8aa1f5b9b426c27409c", "file_sha256": "bfd125c2214b000e420e85998e2384b33c65db06eea26d6f4d87a4f7528f63f0", "terms": ["import", "list", "from", "return", "text", "for", "question", "_model", "embed_text_cached", "and", "answer", "async", "def", "embedding", "embeddings", "float", "jinx", "json", "model", "not", "str", "texts", "that", "__future__", "_cache_path"], "text_preview": "from __future__ import annotations\n\nimport asyncio\nimport json\nimport os\nfrom typing import Dict, List, Tuple\n\nfrom jinx.micro.embeddings.embed_cache import embed_text_cached, embed_texts_cached\n\n# Cache file for prototype embeddings (per model)\n_CACHE_PAT", "dims": 0, "line_start": 1, "line_end": 42}, "embedding": []}