{"meta": {"ts": 1760763311.6824374, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\embeddings\\retrieval_core.py", "chunk_index": 11, "chunks_total": 15, "content_sha256": "570a1148c2213dc2e1b5e609da8b189d7bc6c09f04c884b279f41437152ea6ef", "file_sha256": "e05ba29dfdb5ae19eee2fcb2b9495df4eb10ed18628ca518836d7760ebdafc7f", "terms": ["await", "return", "k_eff", "stage", "_run_sync_stage", "asyncio", "sleep", "ast_hits", "out_hits", "pl_hits", "pydoc_hits", "tb_hits", "lit_res", "list", "sorted", "_merge", "_prj_cache", "now_ms", "proj_stage_pyast_ms", "proj_stage_pydoc_ms", "proj_stage_pyliterals_ms", "proj_stage_tb_ms", "stage_pyast_hits", "stage_pydoc_hits", "stage_pyliterals_hits"], "text_preview": "if isinstance(lit_res, list):\n                _merge(lit_res)\n\n        # Return deduped, score-sorted\n        out_hits = sorted(collected, key=lambda h: float(h[0] or 0.0), reverse=True)[:k_eff]\n        try:\n            _PRJ_CACHE[ck] = (now_ms, list(out_h", "dims": 0, "line_start": 313, "line_end": 348}, "embedding": []}