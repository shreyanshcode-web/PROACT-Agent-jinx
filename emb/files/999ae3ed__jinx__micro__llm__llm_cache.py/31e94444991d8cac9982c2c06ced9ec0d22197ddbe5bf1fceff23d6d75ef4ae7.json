{"meta": {"ts": 1760763312.1324933, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\llm\\llm_cache.py", "chunk_index": 0, "chunks_total": 10, "content_sha256": "31e94444991d8cac9982c2c06ced9ec0d22197ddbe5bf1fceff23d6d75ef4ae7", "file_sha256": "ad8279dac66946bd94b4f35a9a176acfcac7a9a0f2ff619bac11eaa02a9e7323", "terms": ["import", "str", "from", "asyncio", "dict", "getenv", "_tlock", "_max_conc", "time", "except", "exception", "float", "try", "_timeout_ms", "_ttl_sec", "api", "default", "future", "int", "jinx", "tuple", "20s", "__future__", "_dump", "_family_inflight"], "text_preview": "from __future__ import annotations\n\nimport asyncio\nimport hashlib\nimport json\nimport os\nimport time\nfrom typing import Any, Dict, Optional, Tuple, List\nfrom threading import Lock as _TLock\n\nfrom jinx.net import get_openai_client\nfrom jinx.micro.parser.api ", "dims": 0, "line_start": 1, "line_end": 42}, "embedding": []}