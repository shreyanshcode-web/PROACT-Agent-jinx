{"meta": {"ts": 1760763312.2279603, "model": "text-embedding-3-small", "file_rel": "jinx\\micro\\llm\\openai_caller.py", "chunk_index": 3, "chunks_total": 7, "content_sha256": "23d034e8c1c9d27fb98f95a47647dcda3a56a01fda388cf3acdddacbd4144b2f", "file_sha256": "e91d606623d92d919ebc57e554ab08f66200231d2a0789f4a43854f29d44d446", "terms": ["client", "responses", "stream", "code_id", "fs_gate_on", "python_", "none", "str", "extra_kwargs", "input_text", "stream_fn", "getattr", "instructions", "model", "any", "api", "false", "not", "streaming", "try", "_is_code_like", "_queue", "_worker", "build_file_search_tools", "get_openai_client"], "text_preview": "\"\"\"Stream Responses API, fire early when first complete <python_{code_id}> block appears.\n\n    Fallback to validated non-stream call on any streaming error.\n    \"\"\"\n    # File Search gating\n    try:\n        fs_gate_on = (os.getenv(\"JINX_FILESEARCH_GATE\", \"", "dims": 0, "line_start": 97, "line_end": 126}, "embedding": []}