{"meta": {"ts": 1760763309.747337, "model": "text-embedding-3-small", "file_rel": "jinx\\openai_service.py", "chunk_index": 0, "chunks_total": 1, "content_sha256": "25f52ab7bf4a5cac17fc3f6cd52b1a0df7e5d55e7579d3692b93affe7b443d4c", "file_sha256": "5fed470f029afe05a468c7e9ef60bcc50a67889b09326ad51d8f703675fff4d0", "terms": ["code_primer", "spark_openai", "micro", "service", "from", "import", "jinx", "llm", "the", "__all__", "__future__", "annotations", "api", "delegating", "facade", "implementation", "keep", "module", "openai", "public", "stable", "thin", "under", "wrapper"], "text_preview": "\"\"\"OpenAI service facade.\n\nThin wrapper delegating to the micro-module implementation under\n``jinx.micro.llm.service`` to keep the public API stable.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom jinx.micro.llm.service import (\n    code_primer as code_prim", "dims": 0, "line_start": 1, "line_end": 18}, "embedding": []}