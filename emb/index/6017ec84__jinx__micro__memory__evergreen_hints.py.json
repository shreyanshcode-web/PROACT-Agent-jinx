{"file_rel": "jinx\\micro\\memory\\evergreen_hints.py", "file_sha256": "23e81b2313580c43106c08d7703a832fefb6db51d5e3eeff27377638ef161afe", "updated_ts": 1760763312.367271, "total_chunks": 2, "chunks": [{"sha": "1198b3965db901f01e51bf3673356b4e60872180f39f4a5a87b5855ffc7aeaa2", "index": 0, "path": "6017ec84__jinx__micro__memory__evergreen_hints.py\\1198b3965db901f01e51bf3673356b4e60872180f39f4a5a87b5855ffc7aeaa2.json", "terms": ["from", "str", "the", "import", "dict", "channel", "lines", "anchors", "decisions", "list", "paths", "prefs", "symbols", "tokens", "evergreen", "jinx", "memory", "micro", "query", "_select_evg", "optional", "snippet", "__future__", "_expand_tokens", "_read_channel"], "text_preview": "from __future__ import annotations\n\nfrom typing import Dict, List, Optional\n\nfrom jinx.micro.memory.evergreen_select import select_evergreen_for as _select_evg\nfrom jinx.micro.embeddings.project_query_tokens import expand_strong_tokens as _expand_tokens\nfr", "line_start": 1, "line_end": 27}, {"sha": "cb6ef65e0bc98c64475a1db00eccf7c90e95f6045cd391fd2f0674a1a319fedb", "index": 1, "path": "6017ec84__jinx__micro__memory__evergreen_hints.py\\cb6ef65e0bc98c64475a1db00eccf7c90e95f6045cd391fd2f0674a1a319fedb.json", "terms": ["str", "tokens", "_safe_read", "await", "toks_e", "toks_q", "paths", "prefs", "symbols", "list", "except", "exception", "raw", "seen", "try", "_expand_tokens", "max_items", "max_tokens", "decisions", "set", "strip", "and", "for", "from", "kind"], "text_preview": "snip = \"\"\n\n    # Expand strong tokens from both query and snippet\n    toks_q: List[str]\n    toks_e: List[str]\n    try:\n        toks_q = _expand_tokens(q, max_items=max_tokens)\n    except Exception:\n        toks_q = []\n    try:\n        toks_e = _expand_toke", "line_start": 28, "line_end": 67}], "file_terms": ["from", "str", "tokens", "decisions", "paths", "prefs", "symbols", "list", "await", "the", "_safe_read", "import", "lines", "toks_e", "toks_q", "dict", "channel", "evergreen", "except", "exception", "query", "try", "_expand_tokens", "max_tokens", "anchors"]}