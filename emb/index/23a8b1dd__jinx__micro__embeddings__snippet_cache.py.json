{"file_rel": "jinx\\micro\\embeddings\\snippet_cache.py", "file_sha256": "3bb75dd810103c5d39fbe9cf2c093e22ec9144ccf658327f90ffbc197c6bf3c3", "updated_ts": 1760763311.8300679, "total_chunks": 6, "chunks": [{"sha": "dc88c278813f80e909166447b31918ce60064215a86a27c70c52a4156abf7d8b", "index": 0, "path": "23a8b1dd__jinx__micro__embeddings__snippet_cache.py\\dc88c278813f80e909166447b31918ce60064215a86a27c70c52a4156abf7d8b.json", "terms": ["int", "import", "none", "str", "maxv", "minv", "default", "from", "_env_int", "tuple", "cache", "dict", "name", "not", "threading", "__future__", "_cache", "_lock", "_max_entries", "_snippet_ttl_ms", "code_block", "embed_project_snippet_cache_max", "embed_project_snippet_ttl_ms", "is_full_scope", "proj_multi_segment_enable"], "text_preview": "from __future__ import annotations\n\nimport os\nimport time\nimport threading\nimport hashlib\nfrom typing import Any, Dict, List, Optional, Tuple\n\nfrom .project_config import ROOT\nfrom .project_retrieval_config import (\n    PROJ_SNIPPET_PER_HIT_CHARS,\n    PROJ", "line_start": 1, "line_end": 39}, {"sha": "6c1f052e8adbeee516a2aba14be7850d85801e268c706e64ddadf74045cabeca", "index": 1, "path": "23a8b1dd__jinx__micro__embeddings__snippet_cache.py\\6c1f052e8adbeee516a2aba14be7850d85801e268c706e64ddadf74045cabeca.json", "terms": ["int", "return", "str", "file_rel", "def", "time", "except", "exception", "try", "_file_sig", "mt_ns", "clock", "avoid", "for", "signature", "tuple", "_coalesce_wait_ms_default", "_env_int", "_hash_text", "_inflight", "_now_ms", "embed_project_snippet_coalesce_wait_ms", "file_signature", "monotonic_ns", "mtime_ns"], "text_preview": "# Coalescing of concurrent builds\n_Inflight: Dict[str, threading.Event] = {}\n_COALESCE_WAIT_MS_DEFAULT = _env_int(\"EMBED_PROJECT_SNIPPET_COALESCE_WAIT_MS\", 400, minv=0, maxv=2000)\n\n\ndef _now_ms() -> int:\n    # Monotonic clock for TTL to avoid wall-clock ju", "line_start": 40, "line_end": 78}, {"sha": "aed855b6165552941960370fb092a1fb475c455fe72ca270c9a1424a55810449", "index": 2, "path": "23a8b1dd__jinx__micro__embeddings__snippet_cache.py\\aed855b6165552941960370fb092a1fb475c455fe72ca270c9a1424a55810449.json", "terms": ["int", "str", "meta", "file_sig", "else", "key", "query", "extra_centers_abs", "file_rel", "build", "bool", "for", "get", "knobs", "none", "optional", "_file_sig", "_hash_text", "centers_key", "expand_callees", "line_end", "line_start", "make_snippet_cache_key", "prefer_full_scope", "proj_multi_segment_enable"], "text_preview": "def make_snippet_cache_key(\n    file_rel: str,\n    meta: Dict[str, Any],\n    query: str,\n    *,\n    prefer_full_scope: bool,\n    expand_callees: bool,\n    extra_centers_abs: Optional[List[int]],\n    file_sig: Optional[Tuple[int, int]] = None,\n) -> str:\n   ", "line_start": 79, "line_end": 111}, {"sha": "e4d1ec296a06977788d649f858c305164dfb3df91af273db0ede0cac5e7c09d7", "index": 3, "path": "23a8b1dd__jinx__micro__embeddings__snippet_cache.py\\e4d1ec296a06977788d649f858c305164dfb3df91af273db0ede0cac5e7c09d7.json", "terms": ["return", "int", "key", "removed", "_cache", "file_rel", "str", "none", "_lock", "def", "ent", "for", "with", "_snippet_ttl_ms", "to_del", "knobs", "cache", "except", "exception", "not", "now", "pref", "returns", "try", "val"], "text_preview": "key = f\"v1|{file_rel}|{mt}|{sz}|{ls}|{le}|{qh}|pf{int(prefer_full_scope)}|xc{int(expand_callees)}|cent[{centers_key}]|knobs{knobs}\"\n    return key\n\n\ndef get_cached_snippet(key: str) -> Optional[Tuple[str, str, int, int, bool]]:\n    if _SNIPPET_TTL_MS <= 0:", "line_start": 112, "line_end": 153}, {"sha": "96e231377ca3e0a42bbb10a5ae737a10a230a6da15dc26ebbeaa1f7745fdeb2a", "index": 4, "path": "23a8b1dd__jinx__micro__embeddings__snippet_cache.py\\96e231377ca3e0a42bbb10a5ae737a10a230a6da15dc26ebbeaa1f7745fdeb2a.json", "terms": ["str", "return", "none", "int", "key", "_inflight", "def", "event", "wait", "_cache", "_lock", "len", "optional", "threading", "with", "wait_ms", "mode", "and", "clear", "inflight", "leader", "size", "stats", "tuple", "_coalesce_wait_ms_default"], "text_preview": "n = len(_Cache)\n        _Cache.clear()\n        _Inflight.clear()\n        return n\n\n\ndef coalesce_enter(key: str, wait_ms: Optional[int] = None) -> Tuple[str, Optional[threading.Event]]:\n    \"\"\"Return (mode, event). mode is 'leader' or 'wait'.\n\n    If 'wait", "line_start": 154, "line_end": 199}, {"sha": "fe6a54946b5e1b79a909e38339774db5d6ddf1e60ce611442e702ea46d157d35", "index": 5, "path": "23a8b1dd__jinx__micro__embeddings__snippet_cache.py\\fe6a54946b5e1b79a909e38339774db5d6ddf1e60ce611442e702ea46d157d35.json", "terms": ["_cache", "oldest", "key", "_max_entries", "n_evict", "len", "max", "16th", "_lock", "amortize", "and", "ascending", "cap", "continue", "cost", "drop", "entries", "evict", "exceeding", "except", "exception", "first", "for", "ish", "items"], "text_preview": "with _Lock:\n        _Cache[key] = (now, value)\n        # Simple LRU-ish cap: drop oldest entries when exceeding max size\n        if _MAX_ENTRIES > 0 and len(_Cache) > _MAX_ENTRIES:\n            try:\n                # Evict ~1/16th oldest to amortize cost\n  ", "line_start": 200, "line_end": 214}], "file_terms": ["int", "str", "return", "none", "key", "_cache", "def", "file_rel", "for", "tuple", "_lock", "except", "exception", "import", "try", "optional", "with", "_inflight", "cache", "event", "maxv", "minv", "threading", "len", "bool"]}