{"file_rel": "jinx\\micro\\sandbox\\normalizer.py", "file_sha256": "59ac2a51c6a1aff1204ce5962825c5a56f7533ffa550e9f31aa92fd0d2250be7", "updated_ts": 1760763313.4002988, "total_chunks": 2, "chunks": [{"sha": "16d90b011037abd8c67f35b48b25959e305fdef685b05daa8234dddac8fcb2f7", "index": 0, "path": "0be55494__jinx__micro__sandbox__normalizer.py\\16d90b011037abd8c67f35b48b25959e305fdef685b05daa8234dddac8fcb2f7.json", "terms": ["str", "code", "ast", "import", "return", "for", "adump", "def", "none", "_newlines_re", "_stable_ast_dump", "_ws_tail_re", "code_key", "and", "canonicalize", "compile", "dump", "from", "newlines", "sub", "trailing", "tree", "whitespace", "__all__", "__future__"], "text_preview": "from __future__ import annotations\n\nimport ast\nimport hashlib\nimport re\nfrom typing import Tuple\n\n__all__ = [\"code_key\", \"canonicalize\"]\n\n_NEWLINES_RE = re.compile(r\"\\r\\n|\\r|\\n\")\n_WS_TAIL_RE = re.compile(r\"[ \\t]+$\", re.MULTILINE)\n\n\ndef _stable_ast_dump(cod", "line_start": 1, "line_end": 44}, {"sha": "402673cb93f410886f95d87c7d73fea607db26a5584669525ca363f759f37d80", "index": 1, "path": "0be55494__jinx__micro__sandbox__normalizer.py\\402673cb93f410886f95d87c7d73fea607db26a5584669525ca363f759f37d80.json", "terms": ["can", "sha256", "ast", "back", "based", "canonicalization", "canonicalize", "code", "encode", "errors", "falls", "hashlib", "hexdigest", "ignore", "normalized", "possible", "return", "text", "uses", "utf", "when"], "text_preview": "Uses AST-based canonicalization when possible; falls back to normalized text.\n    \"\"\"\n    can = canonicalize(code)\n    h = hashlib.sha256(can.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n    return h", "line_start": 45, "line_end": 49}], "file_terms": ["code", "str", "ast", "return", "import", "for", "adump", "canonicalize", "def", "none", "_newlines_re", "_stable_ast_dump", "_ws_tail_re", "code_key", "and", "can", "compile", "dump", "from", "hashlib", "ignore", "newlines", "sub", "trailing", "tree"]}