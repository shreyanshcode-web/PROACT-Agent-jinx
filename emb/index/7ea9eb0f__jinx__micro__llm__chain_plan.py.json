{"file_rel": "jinx\\micro\\llm\\chain_plan.py", "file_sha256": "42d60fd513a1a2ca3511dba5dd07b614fdbb16fb2008fcc2eb6b7d2bf1d06b9a", "updated_ts": 1760763312.0803795, "total_chunks": 4, "chunks": [{"sha": "1a2dc663881befa3efcfdd715ac57460d2319f747ec9ea2fcb8756eeae70569b", "index": 0, "path": "7ea9eb0f__jinx__micro__llm__chain_plan.py\\1a2dc663881befa3efcfdd715ac57460d2319f747ec9ea2fcb8756eeae70569b.json", "terms": ["from", "import", "llm", "txt", "jinx", "micro", "evid", "optional", "any", "dict", "collect_pre_evidence", "sub_queries", "user_text", "continuity", "evidence", "int", "str", "user", "empty", "not", "note", "planning", "__future__", "chain_evidence", "chain_resilience"], "text_preview": "from __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom jinx.micro.llm.service import spark_openai\nfrom jinx.micro.llm.chain_utils import truthy_env, extract_tagged_block, parse_planner_block, parse_reflection_block\nfrom jinx.micro", "line_start": 1, "line_end": 27}, {"sha": "732c656baf69d51aa62e4f6f7bd782232faf26f51c08b27f783c4beec9bfdae8", "index": 1, "path": "7ea9eb0f__jinx__micro__llm__chain_plan.py\\732c656baf69d51aa62e4f6f7bd782232faf26f51c08b27f783c4beec9bfdae8.json", "terms": ["planner_input", "lines", "cont_block", "anc", "advisory", "else", "plan_mode", "plan_mode_tag", "append", "except", "exception", "get", "join", "pth", "_load_last_anchors", "continuity", "paths", "symbols", "try", "jinx_chained_advisory", "load_last_anchors", "truthy_env", "await", "can", "combined"], "text_preview": "from jinx.micro.conversation.cont import load_last_anchors as _load_last_anchors\n        anc = await _load_last_anchors()\n    except Exception:\n        anc = {}\n    try:\n        lines = []\n        q = (anc.get(\"questions\") or [])[:1]\n        if q:\n        ", "line_start": 28, "line_end": 55}, {"sha": "0cf8b6878c6d21b87fcb20f405488858a2ca677e3c249ee973c3c8752bbd0103", "index": 2, "path": "7ea9eb0f__jinx__micro__llm__chain_plan.py\\0cf8b6878c6d21b87fcb20f405488858a2ca677e3c249ee973c3c8752bbd0103.json", "terms": ["await", "block", "plan", "rbody", "try", "openai_error", "trace_plan", "except", "exception", "out", "phase", "tag", "extract_tagged_block", "no_machine_block", "record_failure", "sub_queries", "advisory", "combined", "data", "error", "goal", "note", "optional", "prompt", "reflect"], "text_preview": "await trace_plan({\"phase\": \"pre\", \"has_evidence\": bool(evid)})\n    try:\n        # Use a single combined prompt with mode controlled by <plan_mode>\n        out, tag = await spark_openai(planner_input, prompt_override=\"planner_advisorycombo\")\n    except Exce", "line_start": 56, "line_end": 83}, {"sha": "a15bd81d32d2f0b40c16f3b3ed7a7032b8d43ba8b1c0fb1995d520d4f1a82a1a", "index": 3, "path": "7ea9eb0f__jinx__micro__llm__chain_plan.py\\a15bd81d32d2f0b40c16f3b3ed7a7032b8d43ba8b1c0fb1995d520d4f1a82a1a.json", "terms": ["data", "kernels_code", "await", "get", "plan", "except", "exception", "len", "extract_tagged_block", "plan_kernels", "plan_len", "record_success", "risks_len", "save_last_plan", "sub_queries", "trace_plan", "and", "good", "kernels", "last", "out", "pass", "path", "persist", "phase"], "text_preview": "kernels_code = extract_tagged_block(out, tag, \"plan_kernels\")\n    except Exception:\n        kernels_code = \"\"\n    if kernels_code:\n        data[\"kernels\"] = kernels_code\n    # Success path: record and persist last good plan\n    try:\n        await record_su", "line_start": 84, "line_end": 101}], "file_terms": ["await", "planner_input", "data", "except", "exception", "from", "import", "try", "plan", "advisory", "lines", "get", "jinx", "llm", "micro", "cont_block", "sub_queries", "trace_plan", "optional", "txt", "anc", "block", "else", "tag", "plan_mode"]}