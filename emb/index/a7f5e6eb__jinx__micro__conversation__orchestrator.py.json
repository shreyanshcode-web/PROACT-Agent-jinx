{"file_rel": "jinx\\micro\\conversation\\orchestrator.py", "file_sha256": "1c159651ee1dd9344340bd1ee38fd659799b6c18881d5af949b5a4baff386b4a", "updated_ts": 1760763310.6652465, "total_chunks": 28, "chunks": [{"sha": "e7e7f708e00de885cbbad14fa51813fa83bbb3f1eb953a76904effc09d6baa96", "index": 0, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\e7e7f708e00de885cbbad14fa51813fa83bbb3f1eb953a76904effc09d6baa96.json", "terms": ["micro", "jinx", "conversation", "from", "embeddings", "memory", "storage", "__future__", "_log_append", "_read_channel", "append_line", "blast_mem", "blue_whispers", "bomb_log", "build_chains", "build_context_for", "build_header", "build_project_context_for", "build_project_context_multi_for", "corrupt_report", "dec_pulse", "embed_text", "ensure_header_block_separation", "error_report", "error_service"], "text_preview": "from __future__ import annotations\n\nimport traceback\nfrom typing import Optional\nimport os\nimport re\nimport asyncio\n\nfrom jinx.logging_service import glitch_pulse, bomb_log, blast_mem\nfrom jinx.openai_service import spark_openai\nfrom jinx.error_service imp", "line_start": 1, "line_end": 25}, {"sha": "f00f8ad8b53055dedb2c5f8b510e461c3e759fa2564e87b9e9a090188a61fb96", "index": 1, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\f00f8ad8b53055dedb2c5f8b510e461c3e759fa2564e87b9e9a090188a61fb96.json", "terms": ["from", "import", "jinx", "micro", "llm", "conversation", "embeddings", "_augment_query", "_chaos_taboo", "_compact_frames", "_ensure_patcher", "_extract_anchors", "_is_short", "_last_q", "_last_u", "_load_last_anchors", "_render_cont_block", "_reuse_proj_ctx", "_sanitize_kernels", "_save_proj_ctx", "_spike_exec", "_topic_shift", "augment_query_for_retrieval", "build_planner_context", "chain_persist"], "text_preview": "from jinx.micro.conversation.memory_sanitize import sanitize_transcript_for_memory\nfrom jinx.micro.embeddings.project_config import ENABLE as PROJ_EMB_ENABLE\nfrom jinx.micro.embeddings.project_paths import PROJECT_FILES_DIR\nfrom jinx.micro.llm.chains impor", "line_start": 26, "line_end": 47}, {"sha": "f244331c60a8acbec4a366beb363501a9040dac9c87c4a282e3fe168fd4d8e1c", "index": 2, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\f244331c60a8acbec4a366beb363501a9040dac9c87c4a282e3fe168fd4d8e1c.json", "terms": ["conversation", "memory", "_append_turn", "_attach_error_code", "_build_api_mem", "_build_mem_ctx", "_build_proj_ctx_enriched", "_ensure_runtime", "_ensure_verifier", "_find_semq", "_infer_turn", "_is_code_like", "_memroute", "_select_evg", "_spark_llm", "_spark_llm_stream", "api_memory", "append_turn", "assemble_memroute", "attach_error_code", "build_api_memory_block", "build_memory_context_for", "build_project_context_enriched", "build_state_frame", "ensure_runtime"], "text_preview": "from jinx.micro.conversation.cont.classify import find_semantic_question as _find_semq\nfrom jinx.micro.conversation.state_frame import build_state_frame\nfrom jinx.micro.memory.router import assemble_memroute as _memroute\nfrom jinx.micro.runtime.api import ", "line_start": 48, "line_end": 60}, {"sha": "650c9bfcdeab09a400eff82670375a483aa9c0e6a63b4b31680514f5486afb3e", "index": 3, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\650c9bfcdeab09a400eff82670375a483aa9c0e6a63b4b31680514f5486afb3e.json", "terms": ["micro", "from", "import", "jinx", "conversation", "try", "await", "ensure", "none", "str", "and", "code", "except", "exception", "memory", "running", "the", "_ensure_patcher", "_ensure_runtime", "_ensure_verifier", "_infer_memsel", "_likely_mem", "_mem_program", "_pins_load", "_turn_jinx"], "text_preview": "from jinx.micro.memory.turns import get_user_message as _turn_user, get_jinx_reply_to as _turn_jinx, parse_active_turns as _turns_all\nfrom jinx.micro.conversation.memory_reasoner import infer_memory_action as _infer_memsel\nfrom jinx.micro.memory.pin_store ", "line_start": 61, "line_end": 83}, {"sha": "32a1e211a70e7c2f03af91f14141730c04c7535cb3f149b8055a471c7c3a0545", "index": 4, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\32a1e211a70e7c2f03af91f14141730c04c7535cb3f149b8055a471c7c3a0545.json", "terms": ["the", "chains", "user", "dialogue", "input", "pass", "strip", "error", "await", "except", "exception", "false", "from", "into", "not", "query", "retrieval", "source", "transcript", "try", "blast_mem", "build_chains", "create_task", "embed_text", "embeddings_context"], "text_preview": "pass\n        except Exception:\n            pass\n        # Append the user input to the transcript first to ensure ordering\n        if x and x.strip():\n            await blast_mem(f\"User: {x.strip()}\")\n            # Also embed the raw user input for retriev", "line_start": 84, "line_end": 105}, {"sha": "09d8215a9cf919cdd1c95df26d430b5d640bb62ee4b12b83fff14f14fad502e5", "index": 5, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\09d8215a9cf919cdd1c95df26d430b5d640bb62ee4b12b83fff14f14fad502e5.json", "terms": ["cur", "semq", "except", "exception", "qline", "synth", "try", "continuity_on", "text", "anchors", "await", "for", "prev", "questions", "then", "_extract_anchors", "_find_semq", "_load_last_anchors", "jinx_continuity_enable", "q_raw", "agnostic", "append", "boost", "cap", "current"], "text_preview": "# Prefer error text for retrieval if present; fallback to user text, then transcript\n            q_raw = (x or err or synth or \"\")\n            continuity_on = str(os.getenv(\"JINX_CONTINUITY_ENABLE\", \"1\")).lower() not in (\"\", \"0\", \"false\", \"off\", \"no\")\n    ", "line_start": 106, "line_end": 130}, {"sha": "9e2b183764660213ba09cc90ee0e0ac634c60388b82c67d69f02c1f7b6ae72f2", "index": 6, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\9e2b183764660213ba09cc90ee0e0ac634c60388b82c67d69f02c1f7b6ae72f2.json", "terms": ["eff_q", "asyncio", "context", "create_task", "mem_ctx_task", "anchors", "base_ctx_task", "cur", "get", "keys", "prev", "set", "except", "exception", "for", "none", "off", "project", "retrieval", "try", "_augment_query", "_build_mem_ctx", "build_context_for", "jinx_embed_memory_ctx", "proj_ctx"], "text_preview": "anchors = {k: list(dict.fromkeys((cur.get(k) or []) + (prev.get(k) or [])))[:10] for k in set((cur or {}).keys()) | set((prev or {}).keys())}\n                eff_q = _augment_query((x or err or \"\"), synth or \"\", anchors=anchors)\n            else:\n         ", "line_start": 131, "line_end": 149}, {"sha": "33e706e16369240d3020e6f25eb536bab682a5e3865ae4f954a104521bfd93d6", "index": 7, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\33e706e16369240d3020e6f25eb536bab682a5e3865ae4f954a104521bfd93d6.json", "terms": ["await", "try", "mem_ctx_task", "mem_ctx", "proj_ctx", "except", "exception", "not", "_build_proj_ctx_enriched", "base_ctx", "proj_ctx_task", "asyncio", "synth", "already", "and", "context", "reuse", "this", "base_ctx_task", "create_task", "user_text", "api", "both", "build", "cached"], "text_preview": "# Delegate enrichment/build to the dedicated micro-module (deduplicated logic)\n            proj_ctx_task: asyncio.Task[str] = asyncio.create_task(_build_proj_ctx_enriched(_q, user_text=x or \"\", synth=synth or \"\"))\n            # Await both contexts; runtime", "line_start": 150, "line_end": 172}, {"sha": "5166225bb5d5b34f2b8ee2c44a853802e1032c37b29892cf01317b804acc6ec5", "index": 8, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\5166225bb5d5b34f2b8ee2c44a853802e1032c37b29892cf01317b804acc6ec5.json", "terms": ["await", "base_ctx", "reuse", "proj_ctx", "except", "exception", "not", "shifted", "topic_shifted", "_reuse_proj_ctx", "ts_check", "runtime", "synth", "try", "_is_short", "_topic_shift", "base_ctx_task", "build_context_for", "eff_q", "jinx_topic_shift_check", "reuse_for_log", "and", "assembly", "bool", "context"], "text_preview": "ts_check = str(os.getenv(\"JINX_TOPIC_SHIFT_CHECK\", \"1\")).lower() not in (\"\", \"0\", \"false\", \"off\", \"no\")\n                    if ts_check and _is_short(x or \"\"):\n                        shifted = await _topic_shift(_q)\n                        topic_shifted =", "line_start": 173, "line_end": 196}, {"sha": "c4e3824e605dc727f6ed50fd4bb2fb025e3ff271a3457162f9d11fe68bbbfd25", "index": 9, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\c4e3824e605dc727f6ed50fd4bb2fb025e3ff271a3457162f9d11fe68bbbfd25.json", "terms": ["anchors", "except", "exception", "plan_ctx", "locals", "optional", "try", "cont_block", "mem_ctx", "turns", "await", "block", "context", "continuity", "else", "for", "llm", "none", "not", "synth", "the", "_is_short", "_last_q", "_last_u", "_render_cont_block"], "text_preview": "except Exception:\n                base_ctx = \"\"\n        if 'mem_ctx' not in locals():\n            mem_ctx = \"\"\n        # Persist last project context snapshot for continuity cache\n        try:\n            await _save_proj_ctx(proj_ctx or \"\", anchors=anchor", "line_start": 197, "line_end": 223}, {"sha": "f2d3a41b1a877c3b11ffda98f74c29a1a2295da98b4b5fdf506972c1d512aa91", "index": 10, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\f2d3a41b1a877c3b11ffda98f74c29a1a2295da98b4b5fdf506972c1d512aa91.json", "terms": ["cap_one", "body", "try", "kind", "except", "exception", "idx", "conf_min", "conf", "get", "and", "await", "confidence", "float", "getenv", "int", "pair", "_infer_turn", "_turn_user", "jinx_turns_conf_min", "jinx_turns_max_chars", "turns_block", "avoid", "false", "gating"], "text_preview": "turns_block = \"\"\n        try:\n            tq = await _infer_turn(x or \"\")\n        except Exception:\n            tq = None\n        if tq:\n            # Confidence gating to avoid false positives\n            try:\n                conf_min = float(os.getenv(\"J", "line_start": 224, "line_end": 251}, {"sha": "a4a4e71bb13920a78365ef479afdf7f9bc74dcca75f43400a55ab15b2d41c762", "index": 11, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\a4a4e71bb13920a78365ef479afdf7f9bc74dcca75f43400a55ab15b2d41c762.json", "terms": ["turns", "body", "idx", "cap_pair", "tiny", "cap_one", "turns_block", "jinx", "len", "strip", "and", "await", "get", "user", "_turn_jinx", "_turns_all", "jinx_turns_pair_max_chars", "elif", "else", "except", "exception", "getenv", "int", "kind", "pair"], "text_preview": "turns_block = f\"<turns>\\n[User:{idx}]\\n{body}\\n</turns>\"\n                    elif kind == \"jinx\":\n                        body = (await _turn_jinx(idx))\n                        if body:\n                            if cap_one > 0 and len(body) > cap_one:\n  ", "line_start": 252, "line_end": 271}, {"sha": "c247e93d7ca8c6ef0947166bcbe8b24768ad0e6db7daf123ebc9a8eb3ea092e1", "index": 12, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\c247e93d7ca8c6ef0947166bcbe8b24768ad0e6db7daf123ebc9a8eb3ea092e1.json", "terms": ["memsel_block", "prog_blocks", "pins", "pins_block", "memory", "except", "exception", "program", "strip", "try", "_likely_mem", "memory_selected", "str", "get", "_mem_program", "turns_block", "any", "await", "back", "blocks", "channels", "compactly", "decide", "dict", "else"], "text_preview": "except Exception:\n                    turns_block = \"\"\n\n        # Optional: memory program â€” plan+execute ops (memroute/pins/topics/channels). Prefer this over simple selector.\n        memsel_block = \"\"\n        prog_blocks: dict[str, str] = {}\n        try:", "line_start": 272, "line_end": 298}, {"sha": "759a209332e6ea67ee4017d9e4734c55a7f2a91b0f2484d6e5692fe966898197", "index": 13, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\759a209332e6ea67ee4017d9e4734c55a7f2a91b0f2484d6e5692fe966898197.json", "terms": ["try", "except", "exception", "get", "params", "mconf_min", "action", "mconf", "float", "getenv", "int", "str", "_infer_memsel", "jinx_memsel_conf_min", "jinx_memsel_k", "memsel_block", "and", "await", "confidence", "lower", "max", "memroute", "min", "none", "not"], "text_preview": "ma = await _infer_memsel(x or \"\")\n            except Exception:\n                ma = None\n        if (not memsel_block) and ma:\n            try:\n                mconf_min = float(os.getenv(\"JINX_MEMSEL_CONF_MIN\", \"0.4\"))\n            except Exception:\n     ", "line_start": 299, "line_end": 327}, {"sha": "d8d02f0a21e0bac8f331e4a228d125d02e82b31cf59087d7a9a2e33d4fe20540", "index": 14, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\d8d02f0a21e0bac8f331e4a228d125d02e82b31cf59087d7a9a2e33d4fe20540.json", "terms": ["body", "pins", "cap", "getenv", "except", "exception", "memory_selected", "memsel_block", "and", "int", "join", "lines", "try", "_memroute", "_pins_load", "jinx_macro_mem_preview_chars", "jinx_memsel_max_chars", "jinx_memsel_preview_chars", "preview_chars", "action", "await", "elif", "for", "len", "max"], "text_preview": "pv = int(os.getenv(\"JINX_MEMSEL_PREVIEW_CHARS\", os.getenv(\"JINX_MACRO_MEM_PREVIEW_CHARS\", \"160\")))\n                            pv = max(24, pv)\n                        except Exception:\n                            pv = 160\n                        lines = a", "line_start": 328, "line_end": 349}, {"sha": "07ecb8d933c594ce8c2a43428f1960a0294de67ea8636112e7137dd166fa3689", "index": 15, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\07ecb8d933c594ce8c2a43428f1960a0294de67ea8636112e7137dd166fa3689.json", "terms": ["fb_k", "body", "getenv", "cap", "except", "exception", "try", "int", "await", "lines", "max", "_likely_mem", "_memroute", "fallback_memroute", "jinx_macro_mem_preview_chars", "jinx_memsel", "jinx_memsel_fallback_k", "jinx_memsel_max_chars", "jinx_memsel_preview_chars", "log_debug", "memsel_block", "preview_chars", "block", "elif", "fallback"], "text_preview": "except Exception:\n                    memsel_block = \"\"\n        elif _likely_mem(x or \"\"):\n            # Fallback path: inject a minimal memroute block using the whole question as query\n            try:\n                await log_debug(\"JINX_MEMSEL\", \"fallb", "line_start": 350, "line_end": 375}, {"sha": "d062c97abef0e169b99e72f11f443efb1ecf396fadf35fc27116fc801c10a4b7", "index": 16, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\d062c97abef0e169b99e72f11f443efb1ecf396fadf35fc27116fc801c10a4b7.json", "terms": ["memory_selected", "plan_kernels", "plan_ctx", "body", "ltag", "pos", "rtag", "memsel_block", "break", "find", "len", "not", "optional", "safe", "_sanitize_kernels", "base_ctx", "cont_block", "embeddings_memory", "jinx_kernels_preload", "proj_ctx", "turns_block", "and", "api", "base", "before"], "text_preview": "memsel_block = f\"<memory_selected>\\n{body}\\n</memory_selected>\"\n            except Exception:\n                pass\n\n        # Do NOT send <embeddings_memory> to API by default; keep only base/project/planner/continuity (+ optional <turns>/<memory_selected>", "line_start": 376, "line_end": 400}, {"sha": "cd82b7b3826aa7f2713a7c5b1946747a5dc66919f78740854fee4afec1495eb3", "index": 17, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\cd82b7b3826aa7f2713a7c5b1946747a5dc66919f78740854fee4afec1495eb3.json", "terms": ["state_frame", "err_msg", "anchors", "err", "cont_block", "_preload_cb", "synth", "and", "await", "code", "else", "except", "exception", "for", "guid", "pass", "str", "strip", "try", "_chaos_taboo", "_spike_exec", "bomb_log", "build_state_frame", "error_summary", "jinx_stateframe_enable"], "text_preview": "pk.append(safe)\n                if pk:\n                    async def _preload_cb(err_msg):\n                        if err_msg:\n                            await bomb_log(f\"kernel preload error: {err_msg}\")\n                    for code in pk:\n              ", "line_start": 401, "line_end": 426}, {"sha": "f3090cbcb5cfd0571ddccb23cff7f220010c2fe6bbed191b701757590a6eaaf7", "index": 18, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\f3090cbcb5cfd0571ddccb23cff7f220010c2fe6bbed191b701757590a6eaaf7.json", "terms": ["await", "except", "exception", "meta", "sha", "try", "_hashlib", "_load_meta", "_save_meta", "frame_sha", "state_frame", "anchors", "frame", "hash", "import", "pass", "_compact_frames", "embed_text", "load_cache_meta", "proj_ctx", "save_last_context_with_meta", "sha256", "also", "attempt", "avoid"], "text_preview": "# Deduplicate by content hash to avoid drift/bloat\n                    import hashlib as _hashlib\n                    from jinx.micro.conversation.cont import load_cache_meta as _load_meta, save_last_context_with_meta as _save_meta\n                    sha ", "line_start": 427, "line_end": 447}, {"sha": "ed3b1567442a6f107c3b686fe30a2271ff71a16c2ed8782d35f564430caa0c41", "index": 19, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\ed3b1567442a6f107c3b686fe30a2271ff71a16c2ed8782d35f564430caa0c41.json", "terms": ["anchors", "evergreen_text", "is_followup", "mem_text", "except", "exception", "false", "not", "try", "jinx_evergreen_send", "q_for_evg", "send_evg", "active", "await", "compact", "default", "else", "evergreen", "getenv", "include", "locals", "lower", "off", "str", "_build_api_mem"], "text_preview": "pass\n        # 2) <memory> from file-based view (active.md or active.compact.md). Default ON.\n        try:\n            is_followup = _is_short(x or \"\")\n        except Exception:\n            is_followup = False\n        try:\n            mem_text = \"\"\n       ", "line_start": 448, "line_end": 470}, {"sha": "b144726c9c03047e472328ec25e79d63087beb4d3c154ed3a89519633f32915d", "index": 20, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\b144726c9c03047e472328ec25e79d63087beb4d3c154ed3a89519633f32915d.json", "terms": ["shifted", "evergreen_text", "except", "exception", "false", "try", "topic_shifted", "await", "getenv", "lower", "not", "off", "pass", "task", "when", "_is_short", "_topic_shift", "jinx_evergreen_topic_guard", "jinx_persist_memory", "mem_text", "persist_memory", "plan_goal", "user_text", "avoid", "bool"], "text_preview": "# Continuity: optionally gate evergreen (when sending) by topic shift on short follow-ups\n        if evergreen_text:\n            try:\n                if str(os.getenv(\"JINX_EVERGREEN_TOPIC_GUARD\", \"1\")).lower() not in (\"\", \"0\", \"false\", \"off\", \"no\"):\n     ", "line_start": 471, "line_end": 492}, {"sha": "8e22c30e0c1089e55a941cbb8ff0350e6aa4cb65e165defdbe5cc025b9b95544", "index": 21, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\8e22c30e0c1089e55a941cbb8ff0350e6aa4cb65e165defdbe5cc025b9b95544.json", "terms": ["err", "else", "anchors", "strip", "chains", "int", "header_text", "task_text", "error_text", "pth_n", "sym_n", "error", "and", "continuity", "get", "len", "locals", "optional", "_is_short", "_log_append", "blue_whispers", "build_header", "evergreen_text", "jinx_continuity_dev_echo", "mem_text"], "text_preview": "#    Continuity augmentation disabled: use only the current user input.\n        if err and err.strip():\n            task_text = \"\"\n        else:\n            task_text = (x or \"\").strip()\n        # Optional <error> block carries execution or prior error det", "line_start": 493, "line_end": 512}, {"sha": "99de3d761ac664f9991cd3d64a77d7b3a081f1086234dc4c9a88963ef4913b1c", "index": 22, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\99de3d761ac664f9991cd3d64a77d7b3a081f1086234dc4c9a88963ef4913b1c.json", "terms": ["decay", "err", "code", "executed_early", "str", "and", "early", "false", "printed_tail_early", "chains", "prompt", "block", "body", "bool", "complete", "error", "first", "guard", "none", "nonlocal", "not", "run", "strip", "when", "_early_exec"], "text_preview": "# If an error is present, enforce a decay hit to drive auto-fix loop\n        if err and err.strip():\n            decay = max(decay, 50)\n        if decay:\n            await dec_pulse(decay)\n        # Final normalization guard\n        chains = ensure_header_", "line_start": 513, "line_end": 534}, {"sha": "a7245c97425cb85bf284a87e0195b53e9c2dbb4e5b90ace67f0e5e9fc6e2e1d3", "index": 23, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\a7245c97425cb85bf284a87e0195b53e9c2dbb4e5b90ace67f0e5e9fc6e2e1d3.json", "terms": ["try", "cid", "await", "the", "body", "except", "exception", "minimal", "not", "payload", "return", "python_", "_early_err", "show_sandbox_tail", "code", "none", "pass", "true", "_attach_error_code", "_is_code_like", "code_body", "corrupt_report", "executed_early", "pretty_echo", "printed_tail_early"], "text_preview": "try:\n                if not _is_code_like(body or \"\"):\n                    return\n            except Exception:\n                # Fail-closed: if heuristic unavailable, do not early-execute\n                return\n            minimal = f\"<python_{cid}>\\n{bo", "line_start": 535, "line_end": 562}, {"sha": "1e62166ce5f3109682bd4c0048f920aa0cc6044a3a58102907adbfa0095cbef9", "index": 24, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\1e62166ce5f3109682bd4c0048f920aa0cc6044a3a58102907adbfa0095cbef9.json", "terms": ["out", "prompt_override", "code_id", "except", "exception", "pass", "the", "await", "model", "output", "err_msg", "printed_out_box", "chains", "ensure", "none", "show", "try", "_early_exec", "_spark_llm", "_spark_llm_stream", "embed_text", "normalize_output_blocks", "on_exec_error", "on_first_block", "pretty_echo"], "text_preview": "await embed_text(minimal.strip(), source=\"dialogue\", kind=\"agent\")\n                    except Exception:\n                        pass\n            except Exception:\n                pass\n\n        if stream_on:\n            out, code_id = await _spark_llm_stre", "line_start": 563, "line_end": 590}, {"sha": "2c4abbf5fd5bb3e1698b316cbdfb15fa9420459438aba13f0727169e4de4a93f", "index": 25, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\2c4abbf5fd5bb3e1698b316cbdfb15fa9420459438aba13f0727169e4de4a93f.json", "terms": ["executed", "await", "code_id", "the", "out", "pairs", "payload", "qtext", "code", "output", "above", "already", "avoid", "core", "model", "not", "raw", "tag", "try", "_attach_error_code", "bomb_log", "corrupt_report", "dec_pulse", "err_msg", "executed_early"], "text_preview": "# Avoid re-printing the same model box; it's already shown above\n            await show_sandbox_tail()\n            # Attach the executed code to the error payload so recovery sees the code to fix\n            payload = _attach_error_code(err_msg or \"\", out,", "line_start": 591, "line_end": 615}, {"sha": "789792d4c8873cc1fbf84d517e57ac5ae4dff67d14c7cde5ca3a7ba4c3f013e7", "index": 26, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\789792d4c8873cc1fbf84d517e57ac5ae4dff67d14c7cde5ca3a7ba4c3f013e7.json", "terms": ["txt", "await", "except", "exception", "out", "qtext", "pass", "strip", "try", "_append_turn", "agent", "also", "append", "based", "best", "dialogue", "effort", "file", "memory", "source", "sub", "the", "turn", "blast_mem", "embed_text"], "text_preview": "txt = re.sub(r\"<[^>]+>.*?</[^>]+>\", \"\", txt, flags=re.DOTALL)\n                    txt = re.sub(r\"<[^>]+>\", \"\", txt)\n                    qtext = txt.strip()\n                except Exception:\n                    qtext = (out or \"\").strip()\n            if qte", "line_start": 616, "line_end": 642}, {"sha": "398b8b2c1b7d5024f47ad69f1ebe7446238879886a552e9b3d6b9cbf31b697b6", "index": 27, "path": "a7f5e6eb__jinx__micro__conversation__orchestrator.py\\398b8b2c1b7d5024f47ad69f1ebe7446238879886a552e9b3d6b9cbf31b697b6.json", "terms": ["import", "await", "_opt_submit", "memory", "snap", "bomb_log", "dec_pulse", "format_exc", "glitch_pulse", "after", "avoids", "circular", "during", "each", "finally", "from", "interaction", "jinx", "late", "micro", "model", "optimization", "optimizer", "per", "run"], "text_preview": "await bomb_log(traceback.format_exc())\n        await dec_pulse(50)\n    finally:\n        # Run memory optimization after each model interaction using a per-turn snapshot\n        snap = await glitch_pulse()\n        # Late import avoids circular import during", "line_start": 643, "line_end": 650}], "file_terms": ["except", "exception", "try", "await", "import", "from", "jinx", "micro", "body", "not", "the", "strip", "getenv", "pass", "str", "anchors", "and", "none", "else", "false", "memory", "get", "for", "conversation", "memsel_block"]}