{"file_rel": "jinx\\settings.py", "file_sha256": "4baa0ceacc772a6ac18914b33afee0b91fe68701bc091a59b2af755c9d972e31", "updated_ts": 1760763309.8656614, "total_chunks": 6, "chunks": [{"sha": "39d72f506ce14bb3290ef8bb017d4f529fd26f8858e31b6344d662eda2d716d7", "index": 0, "path": "df734963__jinx__settings.py\\39d72f506ce14bb3290ef8bb017d4f529fd26f8858e31b6344d662eda2d716d7.json", "terms": ["for", "str", "from", "import", "env", "list", "optional", "raw", "set", "dataclasses", "def", "jinx", "keys", "micro", "modules", "not", "part", "return", "strip", "val", "with", "__future__", "_is_on", "_parse_csv", "env_openai_force_file_search"], "text_preview": "from __future__ import annotations\n\n\"\"\"\nCentralized runtime settings for Jinx.\n\nSingle source of truth for configuration. Values are resolved from environment\nvariables with safe defaults. No hard dependency on .env files; loading those is\nhandled by jinx.", "line_start": 1, "line_end": 38}, {"sha": "94c623c9db520fb1982f47dbcee4b5d62b3c7e2dd49f4a15cdc7a546a7cd26c8", "index": 1, "path": "df734963__jinx__settings.py\\94c623c9db520fb1982f47dbcee4b5d62b3c7e2dd49f4a15cdc7a546a7cd26c8.json", "terms": ["int", "cpus", "return", "true", "cpu_count", "bool", "def", "budget", "cores", "dataclass", "float", "for", "max", "min", "out", "seen", "slots", "with", "_auto_queue_maxsize", "_auto_rt_budget_ms", "_auto_threads", "auto_tune", "autorestart_limit", "backoff_max_ms", "backoff_min_ms"], "text_preview": "continue\n        if p not in seen:\n            seen.add(p)\n            out.append(p)\n    return out\n\n\ndef _auto_threads() -> int:\n    cpus = os.cpu_count() or 4\n    # Favor more threads for I/O bound workloads but keep an upper cap\n    return max(4, min(32", "line_start": 39, "line_end": 81}, {"sha": "dc453bf229a47d8982957f4cf8a5624580ca1f66d9deeeea9b9f632aec4ad083", "index": 2, "path": "df734963__jinx__settings.py\\dc453bf229a47d8982957f4cf8a5624580ca1f66d9deeeea9b9f632aec4ad083.json", "terms": ["str", "openai", "get", "getenv", "none", "proxy", "pulse", "timeout", "int", "default_factory", "vector_store_ids", "model", "openaisettings", "field", "optional", "settings", "openai_api_key", "openai_model", "api_key", "list", "runtimesettings", "any", "class", "dict", "overrides"], "text_preview": "class OpenAISettings:\n    api_key: Optional[str] = None\n    model: str = \"gpt-5\"\n    proxy: Optional[str] = None\n    vector_store_ids: List[str] = field(default_factory=list)\n    force_file_search: bool = True\n\n\n@dataclass(slots=True)\nclass Settings:\n    p", "line_start": 82, "line_end": 110}, {"sha": "c23b0de79a1b5603332e4534f9a59a1213ac495191b194ce782f023f6f530c94", "index": 3, "path": "df734963__jinx__settings.py\\c23b0de79a1b5603332e4534f9a59a1213ac495191b194ce782f023f6f530c94.json", "terms": ["get", "getenv", "str", "int", "autorestart_limit", "backoff_max_ms", "backoff_min_ms", "queue_policy", "_is_on", "hard_rt_budget_ms", "queue_maxsize", "force_file_search", "use_priority_queue", "bool", "runtime", "_auto_queue_maxsize", "_auto_rt_budget_ms", "env_openai_force_file_search", "jinx_autorestart_limit", "jinx_backoff_max_ms", "jinx_backoff_min_ms", "jinx_hard_rt_budget_ms", "jinx_no_supervisor", "jinx_queue_maxsize", "jinx_queue_policy"], "text_preview": "s.openai.force_file_search = bool(\n            _is_on(str(o.get(\"force_file_search\", os.getenv(ENV_OPENAI_FORCE_FILE_SEARCH, \"1\"))))\n        )\n        # Runtime\n        rt = s.runtime\n        rt.queue_maxsize = int(o.get(\"queue_maxsize\", os.getenv(\"JINX_QU", "line_start": 111, "line_end": 125}, {"sha": "9f1c6fb3eb46c2f7ae7f2d2b1916c065a7999538b6fef66dc6117a767d9f757a", "index": 4, "path": "df734963__jinx__settings.py\\9f1c6fb3eb46c2f7ae7f2d2b1916c065a7999538b6fef66dc6117a767d9f757a.json", "terms": ["str", "self", "get", "getenv", "saturate_disable_ratio", "saturate_enable_ratio", "saturate_window_ms", "def", "return", "to_dict", "to_json", "float", "header", "int", "jinx", "print", "settings", "_auto_threads", "_is_on", "auto_tune", "ensure_ascii", "jinx_no_autotune", "jinx_saturate_disable", "jinx_saturate_enable", "jinx_saturate_window_ms"], "text_preview": "rt.threads_max_workers = int(o.get(\"threads\", os.getenv(\"JINX_THREADS\", str(_auto_threads()))))\n        rt.auto_tune = not _is_on(str(o.get(\"no_autotune\", os.getenv(\"JINX_NO_AUTOTUNE\", \"0\"))))\n        try:\n            rt.saturate_enable_ratio = float(o.get", "line_start": 126, "line_end": 149}, {"sha": "2ac160494d771070afb3eed99ddf2030e68f86f9beed4bd3e68bfad5659792c4", "index": 5, "path": "df734963__jinx__settings.py\\2ac160494d771070afb3eed99ddf2030e68f86f9beed4bd3e68bfad5659792c4.json", "terms": ["jx_state", "self", "pulse", "int", "apply_to_state", "boom_limit", "apply", "crash", "def", "except", "exception", "import", "jinx", "keep", "none", "not", "pass", "resilient", "settings", "state", "timeout", "try"], "text_preview": "def apply_to_state(self) -> None:\n        try:\n            import jinx.state as jx_state\n            jx_state.pulse = int(self.pulse)\n            jx_state.boom_limit = int(self.timeout)\n        except Exception:\n            # Do not crash on settings apply", "line_start": 150, "line_end": 157}], "file_terms": ["str", "int", "get", "getenv", "def", "for", "return", "self", "openai", "bool", "none", "settings", "true", "pulse", "cpus", "import", "not", "optional", "_is_on", "timeout", "list", "from", "jinx", "autorestart_limit", "backoff_max_ms"]}