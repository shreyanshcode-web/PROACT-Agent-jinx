{"file_rel": "jinx\\micro\\embeddings\\project_stage_cooccur.py", "file_sha256": "12007dfefcce9699167e01e296096db97168d4886c99be725c2b246626cb846c", "updated_ts": 1760763311.3505309, "total_chunks": 5, "chunks": [{"sha": "b598e817e51a71a93b53e7b3bec353f2efd80ffdd4baa3649be05901dfb443fa", "index": 0, "path": "96a53f29__jinx__micro__embeddings__project_stage_cooccur.py\\b598e817e51a71a93b53e7b3bec353f2efd80ffdd4baa3649be05901dfb443fa.json", "terms": ["import", "from", "str", "continue", "list", "seen", "toks", "_stop", "_token_re", "replace", "set", "and", "def", "for", "len", "limit", "not", "return", "strip", "__future__", "_extract_tokens", "exclude_dirs", "iter_candidate_files", "iter_project_chunks", "max_file_bytes"], "text_preview": "from __future__ import annotations\n\nimport os\nimport re\nimport time\nfrom typing import Any, Dict, List, Tuple\n\nfrom .project_config import ROOT, EXCLUDE_DIRS, MAX_FILE_BYTES\nfrom .project_iter import iter_candidate_files\nfrom .project_scan_store import ite", "line_start": 1, "line_end": 40}, {"sha": "46a494c2d28f35b49863f82fc9908bed98f0b2f70d3fecea760a9beeb73428c9", "index": 1, "path": "96a53f29__jinx__micro__embeddings__project_stage_cooccur.py\\46a494c2d28f35b49863f82fc9908bed98f0b2f70d3fecea760a9beeb73428c9.json", "terms": ["int", "str", "tokens", "lines", "list", "query", "return", "around", "def", "hits", "token", "t_ci", "t_cs", "and", "idx", "least", "len", "lower", "max", "min", "strip", "text", "tuple", "where", "within"], "text_preview": "return toks\n\n\ndef _find_lines(text: str, token: str) -> List[int]:\n    # Case-sensitive then insensitive fallback\n    lines = text.splitlines()\n    hits: List[int] = []\n    t_cs = token\n    t_ci = token.lower()\n    for idx, ln in enumerate(lines, start=1):", "line_start": 41, "line_end": 74}, {"sha": "7a75960d3c43e5ca79fe823e7ba8a8a86d81dcfbbc290193f19f135e3a2de04a", "index": 2, "path": "96a53f29__jinx__micro__embeddings__project_stage_cooccur.py\\7a75960d3c43e5ca79fe823e7ba8a8a86d81dcfbbc290193f19f135e3a2de04a.json", "terms": ["return", "str", "for", "locs", "not", "txt", "list", "false", "len", "tokens", "max_time_ms", "abs_p", "perf_counter", "time_up", "arr", "bool", "continue", "def", "int", "present", "range", "time", "_find_lines", "best_a", "best_b"], "text_preview": "return []\n    t0 = time.perf_counter()\n    out: List[Tuple[float, str, Dict[str, Any]]] = []\n\n    def time_up() -> bool:\n        return max_time_ms is not None and (time.perf_counter() - t0) * 1000.0 > max_time_ms\n\n    def process(abs_p: str, rel_p: str) -", "line_start": 75, "line_end": 109}, {"sha": "05833cc6773b1b584ffd6ef15a41609375550f55790fd23544a4a5c624f2ffb1", "index": 3, "path": "96a53f29__jinx__micro__embeddings__project_stage_cooccur.py\\05833cc6773b1b584ffd6ef15a41609375550f55790fd23544a4a5c624f2ffb1.json", "terms": ["score", "time_up", "break", "else", "best_score", "len", "maxd", "pointer", "best_a", "best_b", "abs", "advance", "and", "base", "bonus", "closer", "for", "line", "lists", "max", "min", "over", "proximity", "sorted", "tokens"], "text_preview": "# Two-pointer over sorted line lists\n                p = 0\n                q2 = 0\n                while p < len(li) and q2 < len(lj):\n                    l1 = li[p]\n                    l2 = lj[q2]\n                    d = abs(l1 - l2)\n                    if", "line_start": 110, "line_end": 140}, {"sha": "0e2972d77ebb82b9526f56a89734f996d4a81b9a500e5d9e82b91f9ece6ac58a", "index": 4, "path": "96a53f29__jinx__micro__embeddings__project_stage_cooccur.py\\0e2972d77ebb82b9526f56a89734f996d4a81b9a500e5d9e82b91f9ece6ac58a.json", "terms": ["rel", "obj", "rel_files", "and", "for", "out", "return", "seen", "str", "exclude_dirs", "max_file_bytes", "best_a", "best_score", "file_rel", "rel_p", "get", "set", "append", "files", "join", "lines", "meta", "root", "snip", "_window"], "text_preview": "if best_score > 0 and best_a > 0:\n            a, b, snip = _window(lines, best_a, best_b)\n            obj = {\n                \"embedding\": [],\n                \"meta\": {\n                    \"file_rel\": rel_p,\n                    \"text_preview\": snip or \"\\n\"", "line_start": 141, "line_end": 173}], "file_terms": ["str", "return", "int", "rel", "list", "for", "tokens", "len", "import", "and", "lines", "from", "not", "def", "out", "seen", "best_score", "time_up", "continue", "false", "score", "strip", "best_a", "set", "append"]}