{"file_rel": "jinx\\micro\\memory\\optimizer.py", "file_sha256": "fd06aaa8fc7aec54936c600667e1093ceb46733b864a41391f780abce05d8d6a", "updated_ts": 1760763312.5471404, "total_chunks": 10, "chunks": [{"sha": "2b39e937dd0041f43d11d5afd823cf2c30386ce2c3ad3e09af8905f8a83ee0ac", "index": 0, "path": "8d29f138__jinx__micro__memory__optimizer.py\\2b39e937dd0041f43d11d5afd823cf2c30386ce2c3ad3e09af8905f8a83ee0ac.json", "terms": ["jinx", "memory", "from", "micro", "import", "and", "state", "__future__", "all_tags", "bomb_log", "build_local_memory", "call_openai", "compact_weekly", "detonate_payload", "get_prompt", "glitch_pulse", "history_compactor", "ingest_memory", "jx_state", "local_builder", "log_paths", "logging_service", "openai_mod", "openai_requests", "openai_requests_dir_memory"], "text_preview": "from __future__ import annotations\n\n\"\"\"Memory optimization pipeline (micro-module).\n\nCollects recent transcript and evergreen memory, asks the LLM to compact\nand persist updated memory state, and serializes executions through a\nsingle worker to preserve or", "line_start": 1, "line_end": 31}, {"sha": "b914000e41f40fe4970d1a51aaeae26c84da1fcbfe1a0814d088c46440a37f52", "index": 1, "path": "8d29f138__jinx__micro__memory__optimizer.py\\b914000e41f40fe4970d1a51aaeae26c84da1fcbfe1a0814d088c46440a37f52.json", "terms": ["none", "str", "asyncio", "snapshot", "await", "lock", "not", "memory", "return", "transcript", "_truthy", "bomb_log", "glitch_pulse", "bool", "call", "def", "default", "evergreen", "false", "name", "optimize", "optional", "single", "try", "_mem_lock"], "text_preview": "# Single worker ensures strict ordering; lock protects model call & writes\n_mem_lock: asyncio.Lock = asyncio.Lock()\n_queue: asyncio.Queue[Tuple[Optional[str], asyncio.Future[None]]] | None = None\n_worker_task: asyncio.Task[None] | None = None\n_stopping: bo", "line_start": 32, "line_end": 63}, {"sha": "64cc32eec1981f5d2c61c9c084e299fec29b49aecbf13cab04a8124759cf40ab", "index": 2, "path": "8d29f138__jinx__micro__memory__optimizer.py\\64cc32eec1981f5d2c61c9c084e299fec29b49aecbf13cab04a8124759cf40ab.json", "terms": ["compact", "token_hint", "durable", "_truthy2", "evergreen", "str", "try", "create_task", "asyncio", "await", "default", "except", "exception", "internally", "name", "not", "return", "throttled", "transcript", "update", "build_local_memory", "ingest_memory", "jinx_mem_emb_enable", "jinx_mem_graph_enable", "read_token_hint"], "text_preview": "if not use_llm:\n            # Local build: compact + evergreen from transcript and previous evergreen\n            try:\n                token_hint = await read_token_hint()\n            except Exception:\n                token_hint = 0\n            compact, du", "line_start": 64, "line_end": 84}, {"sha": "d3180f360c27342100fb765f3cdb3feee249cf387cce14be0c0285f73af9d912", "index": 3, "path": "8d29f138__jinx__micro__memory__optimizer.py\\d3180f360c27342100fb765f3cdb3feee249cf387cce14be0c0285f73af9d912.json", "terms": ["tag_alt", "t_body", "_truthy2", "create_task", "tool_blocks", "and", "asyncio", "durable", "for", "getenv", "list", "pattern", "str", "strip", "transcript", "all_tags", "bomb_log", "compact_weekly", "get_prompt", "jinx_mem_history_compact_enable", "jinx_mem_topics_enable", "memory_optimizer", "memory_timeout_sec", "openai_model", "timeout_sec"], "text_preview": "if durable and _truthy2(\"JINX_MEM_TOPICS_ENABLE\", \"1\"):\n                    asyncio.create_task(update_topics(durable))\n                # Weekly compaction (throttled internally)\n                if _truthy2(\"JINX_MEM_HISTORY_COMPACT_ENABLE\", \"1\"):\n        ", "line_start": 85, "line_end": 109}, {"sha": "1bc3c6ab96019d1ee6bba889514aff47222c5854d2ccaf8fe635802fc47a7831", "index": 4, "path": "8d29f138__jinx__micro__memory__optimizer.py\\1bc3c6ab96019d1ee6bba889514aff47222c5854d2ccaf8fe635802fc47a7831.json", "terms": ["t_body", "transcript", "evergreen", "append", "blocks", "parts", "tool", "e_body", "strip", "sub", "req_path", "blk", "cleaned", "join", "spacing", "str", "_invoke_llm", "input_text", "openai_requests_dir_memory", "target_dir", "tool_blocks", "u00a0", "write_openai_request_dump", "after", "around"], "text_preview": "# Remove tool blocks from transcript text\n            t_body = pattern.sub(\"\", t_body)\n            # Normalize spacing inside transcript (collapse 3+ newlines to 2)\n            t_body = re.sub(r\"\\n{3,}\", \"\\n\", t_body).strip()\n            if t_body:\n       ", "line_start": 110, "line_end": 134}, {"sha": "8246f25093e87aa6f77d5f3f60ccfb30b6511d860c0634d71fd3b32fa24a3db3", "index": 5, "path": "8d29f138__jinx__micro__memory__optimizer.py\\8246f25093e87aa6f77d5f3f60ccfb30b6511d860c0634d71fd3b32fa24a3db3.json", "terms": ["none", "await", "memory", "input_text", "out_text", "instructions", "model", "except", "exception", "bomb_log", "asyncio", "compact", "durable", "optimize", "out", "pass", "task", "timeout", "try", "_invoke_llm", "_queue", "_worker_loop", "call_openai", "detonate_payload", "get_task"], "text_preview": "kind=\"MEMORY\",\n                    instructions=instructions,\n                    input_text=input_text,\n                    model=model,\n                )\n            except Exception:\n                pass\n            out_text = await call_openai(instruct", "line_start": 135, "line_end": 167}, {"sha": "0568714cf02e5257e4bb9454da33f54e7c7297f21a2a7e59657485632789d6b8", "index": 6, "path": "8d29f138__jinx__micro__memory__optimizer.py\\0568714cf02e5257e4bb9454da33f54e7c7297f21a2a7e59657485632789d6b8.json", "terms": ["get_task", "shutdown_task", "asyncio", "await", "with", "contextlib", "done", "not", "suppress", "wait", "create_task", "break", "cancel", "cancellederror", "fut", "none", "shutdown", "snapshot", "the", "_mem_lock", "_optimize_memory_impl", "_queue", "first_completed", "jx_state", "return_when"], "text_preview": "break\n            # Wait for either a queue item or a shutdown signal\n            get_task = asyncio.create_task(_queue.get())\n            shutdown_task = asyncio.create_task(jx_state.shutdown_event.wait())\n            done, pending = await asyncio.wait({g", "line_start": 168, "line_end": 191}, {"sha": "20e8e62ac1782aa9cc3860f72eb533955fde6ea39854d034e12db7894fe8b4f7", "index": 7, "path": "8d29f138__jinx__micro__memory__optimizer.py\\20e8e62ac1782aa9cc3860f72eb533955fde6ea39854d034e12db7894fe8b4f7.json", "terms": ["not", "none", "get_task", "shutdown_task", "contextlib", "suppress", "with", "_queue", "asyncio", "baseexception", "cancellederror", "done", "fut", "runtimeerror", "loop", "and", "await", "cancel", "except", "exception", "finally", "_ensure_worker", "_worker_task", "set_exception", "set_result"], "text_preview": "fut.set_result(None)\n            except Exception as e:  # propagate to caller\n                with contextlib.suppress(BaseException):\n                    if not fut.done():\n                        fut.set_exception(e)\n            finally:\n               ", "line_start": 192, "line_end": 218}, {"sha": "0e8996696573d1d3a79d200374000e8deab56a144991ff638d6c0f392102d386", "index": 8, "path": "8d29f138__jinx__micro__memory__optimizer.py\\0e8996696573d1d3a79d200374000e8deab56a144991ff638d6c0f392102d386.json", "terms": ["none", "_worker_task", "_queue", "asyncio", "and", "not", "_stopping", "await", "fut", "shutdown", "worker", "is_set", "jx_state", "shutdown_event", "async", "cancel", "def", "drain", "memory", "optimizer", "queue", "return", "snapshot", "stop", "submit"], "text_preview": "_queue = asyncio.Queue(maxsize=32)\n    # Do not start during shutdown or when stopping\n    if jx_state.shutdown_event.is_set() or _stopping:\n        return\n    if _worker_task is None or _worker_task.done():\n        _worker_task = asyncio.create_task(_work", "line_start": 219, "line_end": 250}, {"sha": "2d2bbb6d651404dc98dea09637df983853b177d6ebb492c768f273efa51b72cd", "index": 9, "path": "8d29f138__jinx__micro__memory__optimizer.py\\2d2bbb6d651404dc98dea09637df983853b177d6ebb492c768f273efa51b72cd.json", "terms": ["_worker_task", "asyncio", "return", "none", "task", "the", "not", "fut", "_queue", "and", "cancellederror", "done", "memory", "noop", "optimizer", "_ensure_worker", "_stopping", "create_task", "get_nowait", "set_exception", "start_memory_optimizer_task", "task_done", "already", "await", "background"], "text_preview": "snapshot, fut = _queue.get_nowait()\n                if not fut.done():\n                    fut.set_exception(asyncio.CancelledError())\n                _queue.task_done()\n        except asyncio.QueueEmpty:\n            pass\n    if _worker_task is not None an", "line_start": 251, "line_end": 275}], "file_terms": ["none", "asyncio", "await", "memory", "not", "import", "from", "and", "jinx", "_worker_task", "str", "transcript", "return", "_queue", "get_task", "shutdown_task", "with", "evergreen", "done", "fut", "t_body", "except", "micro", "try", "snapshot"]}