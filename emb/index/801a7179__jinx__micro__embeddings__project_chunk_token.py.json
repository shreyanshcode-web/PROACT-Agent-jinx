{"file_rel": "jinx\\micro\\embeddings\\project_chunk_token.py", "file_sha256": "0eebc036a828f378228112cd9c969199d150dded295afb6faea5e6f2a5079b88", "updated_ts": 1760763311.0344625, "total_chunks": 2, "chunks": [{"sha": "3be73db06daa7ba5f97b454343427d17ab2c6c4c947cd0e653efb45f51e36f73", "index": 0, "path": "801a7179__jinx__micro__embeddings__project_chunk_token.py\\3be73db06daa7ba5f97b454343427d17ab2c6c4c947cd0e653efb45f51e36f73.json", "terms": ["text", "none", "enc", "int", "import", "list", "return", "tiktoken", "chunk", "except", "exception", "from", "getenv", "str", "toks", "try", "_tiktoken_encode", "def", "token", "__future__", "chunk_text_token", "cl100k_base", "embed_project_max_chunks_per_file", "embed_project_min_chunk_tokens", "embed_project_tokens_per_chunk"], "text_preview": "from __future__ import annotations\n\nimport os\nfrom typing import List\nfrom .project_chunk_types import Chunk\n\n# Token-based chunking parameters\nTOKENS_PER_CHUNK = int(os.getenv(\"EMBED_PROJECT_TOKENS_PER_CHUNK\", \"300\"))\nMIN_CHUNK_TOKENS = int(os.getenv(\"EMB", "line_start": 1, "line_end": 40}, {"sha": "3611a38e27f29f28c615458a03983ed009c62a0081536c51a5f99ce49311827f", "index": 1, "path": "801a7179__jinx__micro__embeddings__project_chunk_token.py\\3611a38e27f29f28c615458a03983ed009c62a0081536c51a5f99ce49311827f.json", "terms": ["sub_text", "chunks", "sub", "and", "len", "line_end", "line_start", "max_chunks_per_file", "min_chunk_tokens", "tokens_per_chunk", "append", "break", "chunk", "decode", "enc", "except", "exception", "min", "return", "strip", "text", "toks", "try", "while"], "text_preview": "i = 0\n    while i < n and len(chunks) < MAX_CHUNKS_PER_FILE:\n        j = min(n, i + TOKENS_PER_CHUNK)\n        sub = toks[i:j]\n        if len(sub) < MIN_CHUNK_TOKENS and chunks:\n            break\n        try:\n            sub_text = enc.decode(sub).strip()\n ", "line_start": 41, "line_end": 54}], "file_terms": ["text", "enc", "none", "return", "int", "chunks", "import", "list", "sub_text", "chunk", "except", "exception", "tiktoken", "toks", "try", "from", "getenv", "len", "str", "sub", "_tiktoken_encode", "line_end", "line_start", "max_chunks_per_file", "min_chunk_tokens"]}