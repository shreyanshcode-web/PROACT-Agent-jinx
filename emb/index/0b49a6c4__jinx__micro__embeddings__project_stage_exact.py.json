{"file_rel": "jinx\\micro\\embeddings\\project_stage_exact.py", "file_sha256": "db46be9ed965e1019575af48cff2033907d153c44a8ffc76edcd58276e2c92cb", "updated_ts": 1760763311.310858, "total_chunks": 2, "chunks": [{"sha": "5daf7111442bc3602404cb7ee4c51b2f23842a7446b4e5842df59f5111062598", "index": 0, "path": "0b49a6c4__jinx__micro__embeddings__project_stage_exact.py\\5daf7111442bc3602404cb7ee4c51b2f23842a7446b4e5842df59f5111062598.json", "terms": ["str", "import", "from", "code_toks", "meta", "list", "any", "dict", "get", "obj", "tuple", "expand_strong_tokens", "file_rel", "iter_project_chunks", "proj_max_chunks_per_file", "proj_max_files", "int", "score", "set", "float", "for", "not", "query", "return", "terms"], "text_preview": "from __future__ import annotations\n\nimport os\nimport time\nfrom typing import Any, Dict, List, Tuple\n\nfrom .project_scan_store import iter_project_chunks\nfrom .project_retrieval_config import (\n    PROJ_MAX_FILES,\n    PROJ_MAX_CHUNKS_PER_FILE,\n)\nfrom .proje", "line_start": 1, "line_end": 34}, {"sha": "b8f7b5079cf8f158f27536a8ce83822feba0f1b722a703490e41023f695ebd47", "index": 1, "path": "0b49a6c4__jinx__micro__embeddings__project_stage_exact.py\\b8f7b5079cf8f158f27536a8ce83822feba0f1b722a703490e41023f695ebd47.json", "terms": ["file_rel", "not", "exact_hits", "lower", "txt", "and", "for", "max_time_ms", "code_toks", "seen_files", "file", "any", "hay", "low", "path", "read", "return", "str", "true", "try", "hay_terms", "perf_counter", "add", "append", "break"], "text_preview": "hay = (pv + \" \" + hay_terms + \" \" + str(file_rel)).lower()\n        ok = any(t.lower() in hay for t in code_toks)\n        # If not matched in preview/terms/path, try a single read of the file text for this file\n        if not ok and file_rel and file_rel no", "line_start": 35, "line_end": 57}], "file_terms": ["file_rel", "str", "not", "import", "code_toks", "from", "exact_hits", "meta", "any", "for", "get", "list", "lower", "obj", "return", "txt", "max_time_ms", "seen_files", "and", "dict", "path", "terms", "time", "tuple", "expand_strong_tokens"]}