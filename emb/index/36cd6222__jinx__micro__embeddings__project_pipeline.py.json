{"file_rel": "jinx\\micro\\embeddings\\project_pipeline.py", "file_sha256": "85de40621c264b4553609881b4ca0b4cb1ae13b413fe0b3c9b87cf903c51bb78", "updated_ts": 1760763311.1385107, "total_chunks": 6, "chunks": [{"sha": "61e178d1dd9345a6f01a8c4492d981964b85494e938f231e5cf34905e03d1743", "index": 0, "path": "36cd6222__jinx__micro__embeddings__project_pipeline.py\\61e178d1dd9345a6f01a8c4492d981964b85494e938f231e5cf34905e03d1743.json", "terms": ["import", "from", "list", "model", "return", "text", "texts", "embed_text_cached", "embed_texts_cached", "async", "await", "def", "except", "exception", "float", "getenv", "str", "try", "__future__", "_embed_text", "_embed_texts", "chunk_text_char", "chunk_text_token", "chunker_kind", "embed_cache"], "text_preview": "from __future__ import annotations\n\nimport asyncio\nimport json\nimport os\nimport hashlib\nfrom typing import Any, Dict, List, Tuple\n\nfrom .project_paths import (\n    ensure_project_dirs,\n    PROJECT_FILES_DIR,\n    PROJECT_INDEX_DIR,\n    safe_rel_path,\n)\nfrom", "line_start": 1, "line_end": 43}, {"sha": "84d7e710da28750f4c14ca0429cb2c863f4287d18b6ab3b5071b2bf89ad4ea69", "index": 1, "path": "36cd6222__jinx__micro__embeddings__project_pipeline.py\\84d7e710da28750f4c14ca0429cb2c863f4287d18b6ab3b5071b2bf89ad4ea69.json", "terms": ["str", "return", "def", "text", "index", "emb", "file", "toks", "_read_file", "abs_path", "file_dir", "full_text", "rel_path", "safe_rel", "chunker", "and", "chunk", "json", "list", "per", "read", "safe", "token", "true", "_chunk_text"], "text_preview": "def _file_terms(full_text: str) -> List[str]:\n    return extract_terms(full_text)\n\n\ndef _chunk_text(text: str) -> List[Chunk]:\n    \"\"\"Select chunker per env; fallback to char-based if token chunker unavailable.\"\"\"\n    if CHUNKER_KIND == \"token\":\n        to", "line_start": 44, "line_end": 77}, {"sha": "2850827d141a4f4da1da3a6b734279143b84f4ac091ae0b6c7a23c1dd8083376", "index": 2, "path": "36cd6222__jinx__micro__embeddings__project_pipeline.py\\2850827d141a4f4da1da3a6b734279143b84f4ac091ae0b6c7a23c1dd8083376.json", "terms": ["str", "int", "ch_obj", "seen_chunks", "list", "csha", "data", "text", "_chunk_and_terms", "chunk_items", "file_terms", "index_path", "line_start", "to_thread", "set", "and", "asyncio", "await", "chunks", "get", "return", "tuple", "_chunk_text", "_file_terms", "file_rel"], "text_preview": "index_path = os.path.join(PROJECT_INDEX_DIR, f\"{safe}.json\")\n        data = {\n            \"file_rel\": rel_path,\n            \"file_sha256\": file_sha,\n            \"updated_ts\": now_ts(),\n            \"total_chunks\": 0,\n            \"chunks\": [],\n            \"f", "line_start": 78, "line_end": 107}, {"sha": "a269ec0b320ff85f3936a8ecda2c72d35fddd853b6145855133643fb4bef6cf8", "index": 3, "path": "36cd6222__jinx__micro__embeddings__project_pipeline.py\\a269ec0b320ff85f3936a8ecda2c72d35fddd853b6145855133643fb4bef6cf8.json", "terms": ["unique_inputs", "vec", "csha", "len", "payload", "batch_vecs", "chunks_total", "idx", "meta", "str", "for", "results", "batch_texts", "line_end", "model", "any", "append", "dict", "else", "unique", "_embed_texts", "ch_obj", "chunk_index", "chunk_sha", "content_sha256"], "text_preview": "le = int(ch_obj.get(\"line_end\") or 0)\n        unique_inputs.append((i, ch, csha, ls, le))\n\n    batch_texts = [t[1] for t in unique_inputs]\n    batch_vecs = await _embed_texts(batch_texts)\n\n    results: List[Tuple[str, Dict[str, Any]]] = []  # (chunk_sha, p", "line_start": 108, "line_end": 137}, {"sha": "3a445b919386e9e733644888802073bf23c49f397cde4318e5186a4c016c7874", "index": 4, "path": "36cd6222__jinx__micro__embeddings__project_pipeline.py\\3a445b919386e9e733644888802073bf23c49f397cde4318e5186a4c016c7874.json", "terms": ["asyncio", "write_tasks", "csha", "dir_path", "except", "for", "json", "keep", "payload", "_prune", "file_dir", "keep_names", "to_thread", "str", "await", "chunk", "exception", "files", "join", "path", "results", "return", "set", "try", "write"], "text_preview": "payload.get(\"meta\", {})[\"chunks_total\"] = total_unique\n\n    # Write new chunk files (atomic replace) off the event loop\n    write_tasks: List[asyncio.Task] = []\n    for csha, payload in results:\n        p = os.path.join(file_dir, f\"{csha}.json\")\n        wr", "line_start": 138, "line_end": 165}, {"sha": "1328712d1dd0f60a2f586fd0151366c70e04a7ee4cde50e0c00ffb496b774a5b", "index": 5, "path": "36cd6222__jinx__micro__embeddings__project_pipeline.py\\1328712d1dd0f60a2f586fd0151366c70e04a7ee4cde50e0c00ffb496b774a5b.json", "terms": ["get", "payload", "meta", "path", "index_obj", "csha", "file_terms", "line_end", "line_start", "text_preview", "index_path", "terms", "join", "json", "results", "chunk_index", "file_dir", "file_rel", "file_sha", "file_sha256", "now_ts", "project_files_dir", "project_index_dir", "rel_path", "to_thread"], "text_preview": "index_path = os.path.join(PROJECT_INDEX_DIR, f\"{safe}.json\")\n    index_obj = {\n        \"file_rel\": rel_path,\n        \"file_sha256\": file_sha,\n        \"updated_ts\": now_ts(),\n        \"total_chunks\": len(results),\n        \"chunks\": [\n            {\n          ", "line_start": 166, "line_end": 192}], "file_terms": ["str", "get", "csha", "import", "return", "payload", "list", "asyncio", "for", "from", "text", "meta", "await", "json", "path", "def", "except", "model", "exception", "results", "try", "to_thread", "unique_inputs", "chunk", "join"]}