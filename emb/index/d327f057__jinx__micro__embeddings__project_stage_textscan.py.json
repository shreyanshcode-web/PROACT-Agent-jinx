{"file_rel": "jinx\\micro\\embeddings\\project_stage_textscan.py", "file_sha256": "09414a7c63bd3495867b169d4c9f87748353256f89e5719d09ccb60034362c60", "updated_ts": 1760763311.6231713, "total_chunks": 12, "chunks": [{"sha": "d2b3e85331e9c569f5f7dcac7c456aa4f255dafe8f4253b3bb8f30605d841ef6", "index": 0, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\d2b3e85331e9c569f5f7dcac7c456aa4f255dafe8f4253b3bb8f30605d841ef6.json", "terms": ["import", "str", "from", "max_items", "list", "int", "out", "seen", "strong", "codeish_tokens", "expand_strong_tokens", "set", "any", "def", "dict", "simple", "text", "tuple", "__future__", "_expand_tokens", "_is_code_like", "_re", "exclude_dirs", "find_line_window", "include_exts"], "text_preview": "from __future__ import annotations\n\nimport os\nimport time\nfrom typing import Any, Dict, List, Tuple\nimport re as _re\n\nfrom .project_config import ROOT, INCLUDE_EXTS, EXCLUDE_DIRS, MAX_FILE_BYTES\nfrom .project_iter import iter_candidate_files\nfrom .project_", "line_start": 1, "line_end": 33}, {"sha": "ad92afe7278673aa7ea4fe05bcb4867b84ef70770277161c1659410c77d7c74d", "index": 1, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\ad92afe7278673aa7ea4fe05bcb4867b84ef70770277161c1659410c77d7c74d.json", "terms": ["str", "code", "def", "list", "query", "return", "strip", "__re", "score", "set", "flexible", "len", "match", "none", "phrase", "src", "the", "try", "whitespace", "__ast", "_can_parse", "_expand_tokens", "_extract_code_core", "_flex_phrase_pattern", "file_rel"], "text_preview": "- First tries a flexible phrase match (whitespace-insensitive, tolerant around ()=, ,)\n    - Then falls back to token scanning using code-like tokens.\n\n    Returns a list of (score, file_rel, obj) sorted by score desc.\n    \"\"\"\n    q = (query or \"\").strip()", "line_start": 34, "line_end": 62}, {"sha": "0cc2539a7f85bf9b901e3df29898caa417c61ded573ea600f2015ea607c607c1", "index": 2, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\0cc2539a7f85bf9b901e3df29898caa417c61ded573ea600f2015ea607c607c1.json", "terms": ["frag", "return", "best", "__ast", "best_len", "group", "strip", "cands", "except", "exception", "len", "mode", "parse", "true", "try", "eval", "for", "pass", "_can_parse", "frag2", "and", "candidate", "choose", "continue", "exec"], "text_preview": "try:\n                        __ast.parse(s, mode='exec')\n                        return True\n                    except Exception:\n                        pass\n                    try:\n                        __ast.parse(s, mode='eval')\n                   ", "line_start": 63, "line_end": 91}, {"sha": "3047476e23b0419eb14787f01a1b92d4aa9eeaf9a5575f89fc821e441420823a", "index": 3, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\3047476e23b0419eb14787f01a1b92d4aa9eeaf9a5575f89fc821e441420823a.json", "terms": ["_rx", "return", "none", "rel", "seen_f", "for", "needle", "parts", "regex", "str", "s_eff", "get", "set", "and", "err", "except", "exception", "not", "obj", "try", "_extract_code_core", "_flex_phrase_pattern", "file_rel", "frag2", "iter_project_chunks"], "text_preview": "return frag2 or None\n                return None\n            except Exception:\n                return None\n        s_eff = _extract_code_core(s) or s\n        parts = [p for p in s_eff.split() if p]\n        if not parts:\n            return None\n        # Bu", "line_start": 92, "line_end": 119}, {"sha": "3d134a138c0ad1cbb4ca2c13401ff3416818e23e8cbd6a953a8665c7b44aa5b7", "index": 4, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\3d134a138c0ad1cbb4ca2c13401ff3416818e23e8cbd6a953a8665c7b44aa5b7.json", "terms": ["text", "str", "not", "try", "rel_p", "false", "rel", "return", "max_time_ms", "abs_p", "rel_files", "seen_rel", "except", "exception", "none", "time", "_is_code_like", "_scan_abs_rel", "is_phrase_hit", "le_meta", "ls_meta", "perf_counter", "phrase_pat", "texts_to_try", "add"], "text_preview": "# If query is code-like, prefer Python files only\n                if (not _is_code_like(q)) or rel.endswith('.py'):\n                    rel_files.append(rel)\n    except Exception:\n        rel_files = []\n\n    def _scan_abs_rel(abs_p: str, rel_p: str) -> boo", "line_start": 120, "line_end": 149}, {"sha": "4c37c5d8879beba053a3f37b75937fd1a4e3b07fc5e731d82db975fe254488ba", "index": 5, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\4c37c5d8879beba053a3f37b75937fd1a4e3b07fc5e731d82db975fe254488ba.json", "terms": ["texts_to_try", "append", "except", "exception", "pass", "text", "gen_strip", "gen_t", "no_punct", "no_unders", "_re", "src", "sub", "try", "pos0", "for", "pre", "remove", "_kind", "phrase_pat", "pos1", "queue_t", "comments", "count", "docstrings"], "text_preview": "gen_strip = _re.sub(r\"\\[[^\\]\\n]*\\]\", \"\", text)\n                texts_to_try.append((\"gen_strip\", gen_strip))\n            except Exception:\n                pass\n            try:\n                gen_T = _re.sub(r\"\\[[^\\]\\n]*\\]\", \"T\", text)\n                tex", "line_start": 150, "line_end": 176}, {"sha": "9da4700f01482207229bfee1acf8f8e3ba56019d0cdca0e67eef55a8d3eb44db", "index": 6, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\9da4700f01482207229bfee1acf8f8e3ba56019d0cdca0e67eef55a8d3eb44db.json", "terms": ["le_meta", "ls_meta", "not", "text", "_df", "lines_all", "match", "snip", "snip2", "and", "approximate", "int", "low", "lower", "max", "none", "strip", "toks", "find_line_window", "is_phrase_hit", "pos0", "pos1", "anchors", "any", "around"], "text_preview": "le = ls + max(1, src[pos0:pos1].count(\"\\n\"))\n                    lines_all = text.splitlines()\n                    a = max(1, ls - 12)\n                    b = min(len(lines_all), le + 12)\n                    snip = \"\\n\".join(lines_all[a-1:b]).strip()\n     ", "line_start": 177, "line_end": 201}, {"sha": "80c48925ec5fd90acb2250eedb5bf9346fb3736a84781e15170f6010a8580626", "index": 7, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\80c48925ec5fd90acb2250eedb5bf9346fb3736a84781e15170f6010a8580626.json", "terms": ["best", "lines_all", "len", "and", "idx", "anchors", "for", "max_time_ms", "a_tok", "ln_low", "max_lines", "lower", "min", "none", "time", "_df", "perf_counter", "bail", "bound", "break", "budget", "check", "exceeds", "key", "lines"], "text_preview": "anchors = sorted({t for t in toks if t and len(t) >= 5}, key=len, reverse=True)[:3]\n                    if anchors:\n                        lines_all = text.splitlines()\n                        # Bound work: check up to N lines and bail if time budget exce", "line_start": 202, "line_end": 220}, {"sha": "908bb5e13a5a96bef1fd5acc2c46660bee1e36b28346ce42c33694b33c79bf02", "index": 8, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\908bb5e13a5a96bef1fd5acc2c46660bee1e36b28346ce42c33694b33c79bf02.json", "terms": ["str", "try", "except", "exception", "ignore", "none", "type", "_df2", "_re", "_rf_fuzz", "le_meta", "ls_meta", "snip", "def", "fuzzy", "import", "join", "src", "_extract_code_core2", "_norm", "lines_all", "and", "code", "core", "cover"], "text_preview": "snip = snip or \"\\n\".join(lines_all[a-1:b]).strip()\n                            ls_meta = a\n                            le_meta = b\n        # Final fallback: fuzzy full-query vs individual lines (very tolerant)\n        if not (ls_meta and le_meta):\n        ", "line_start": 221, "line_end": 247}, {"sha": "8b12d6fb1e0bc866cd4cf44cd642d608f0588e221f9a3c1f3887197cebb4170d", "index": 9, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\8b12d6fb1e0bc866cd4cf44cd642d608f0588e221f9a3c1f3887197cebb4170d.json", "terms": ["lines_all", "except", "exception", "none", "return", "max_time_ms", "_norm", "_rf_fuzz", "core_q", "max_lines", "and", "for", "group", "idx", "len", "not", "pass", "score", "strip", "try", "_extract_code_core2", "_re", "best_idx", "best_score", "perf_counter"], "text_preview": "return (m.group(1) or \"\").strip()\n                except Exception:\n                    pass\n                try:\n                    # Fallback: look for a call-like pattern\n                    m2 = _re.search(r\"([A-Za-z_][A-Za-z0-9_\\.]*)\\s*\\(.*\\)\", src)\n", "line_start": 248, "line_end": 274}, {"sha": "0effea7c7402e643ce8d0d1e88611e2771b1981e2d4f76f187ede8e97eacb27d", "index": 10, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\0effea7c7402e643ce8d0d1e88611e2771b1981e2d4f76f187ede8e97eacb27d.json", "terms": ["score", "best_idx", "hits", "best_score", "snip", "_df2", "le_meta", "lines_all", "ls_meta", "rel_p", "len", "none", "obj", "return", "strip", "file_rel", "is_phrase_hit", "line_end", "line_start", "text_preview", "and", "append", "elif", "else", "embedding"], "text_preview": "score = 0.0\n                    elif _df2 is not None:\n                        try:\n                            score = _df2.SequenceMatcher(None, nq, ln).ratio()\n                        except Exception:\n                            score = 0.0\n           ", "line_start": 275, "line_end": 305}, {"sha": "ae1fed807a3772aacceec3c6414b75158b94ce7a66dfc627c7ec58bcbe42bf43", "index": 11, "path": "d327f057__jinx__micro__embeddings__project_stage_textscan.py\\ae1fed807a3772aacceec3c6414b75158b94ce7a66dfc627c7ec58bcbe42bf43.json", "terms": ["rel_p", "include_exts", "abs_p", "hits", "return", "exclude_dirs", "max_file_bytes", "_scan_abs_rel", "codey", "for", "root", "_is_code_like", "iter_candidate_files", "rel_files", "all", "else", "embeddings", "equal", "fallback", "files", "first", "general", "join", "keep", "known"], "text_preview": "# Scan embeddings-known files first\n    for rel_p in rel_files:\n        abs_p = os.path.join(ROOT, rel_p)\n        if _scan_abs_rel(abs_p, rel_p):\n            return hits[:k]\n\n    # Pass 2: fallback to general project walk (slower)\n    codey = _is_code_like", "line_start": 306, "line_end": 325}], "file_terms": ["return", "str", "none", "try", "except", "exception", "text", "not", "for", "import", "len", "lines_all", "and", "strip", "rel_p", "score", "pass", "from", "le_meta", "ls_meta", "snip", "best", "list", "src", "hits"]}